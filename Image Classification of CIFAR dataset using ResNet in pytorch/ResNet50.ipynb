{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600341365391",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import pdb\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "torch.set_printoptions(linewidth = 120) \n",
    "torch.set_grad_enabled(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeck(nn.Module):\n",
    "\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride = 1, dim_change = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = stride, padding = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size = 1) #expanding to dim of 4 \n",
    "        self.bn3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        self.dim_change = dim_change\n",
    "\n",
    "    def forward(self,x):\n",
    "        res = x\n",
    "        \n",
    "        output = F.relu(self.bn1(self.conv1(x)))\n",
    "        output = F.relu(self.bn2(self.conv2(output)))\n",
    "        output = self.bn3(self.conv3(output))\n",
    "\n",
    "        if self.dim_change is not None:\n",
    "            res = self.dim_change(res)\n",
    "        \n",
    "        output += res\n",
    "        output = F.relu(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, num_layers, classes=10):\n",
    "\n",
    "        super().__init__()\n",
    "   \n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.layer1 = self._layer(block,64,num_layers[0],stride=1)\n",
    "        self.layer2 = self._layer(block,128,num_layers[1],stride=2)\n",
    "        self.layer3 = self._layer(block,256,num_layers[2],stride=2)\n",
    "        self.layer4 = self._layer(block,512,num_layers[3],stride=2 )\n",
    "        self.averagePool = nn.AvgPool2d(kernel_size=4,stride=1)\n",
    "        self.fc = nn.Linear(512*block.expansion,classes)\n",
    "    \n",
    "    def _layer(self,block,out_channels,num_layers,stride=1):\n",
    "        \n",
    "        dim_change = None\n",
    "        if stride!=1 or out_channels != self.in_channels*block.expansion:\n",
    "            dim_change = nn.Sequential(\n",
    "                                nn.Conv2d(self.in_channels,out_channels*block.expansion,kernel_size=1,stride=stride),nn.BatchNorm2d(out_channels*block.expansion))\n",
    "            \n",
    "        netLayers =[]\n",
    "        netLayers.append(block(self.in_channels,out_channels,stride=stride,dim_change=dim_change))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for i in range(1,num_layers):\n",
    "            netLayers.append(block(self.in_channels,out_channels))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        \n",
    "        return nn.Sequential(*netLayers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = F.avg_pool2d(x,4)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "        #To convert data from PIL to tensor\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "        )\n",
    "\n",
    "    #Load train and test set:\n",
    "    train = torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
    "    trainset = torch.utils.data.DataLoader(train,batch_size=128,shuffle=True)\n",
    "\n",
    "    test = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n",
    "    testset = torch.utils.data.DataLoader(test,batch_size=128,shuffle=False)\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    #ResNet-18 \n",
    "    #net = ResNet(baseBlock,[2,2,2,2],10)\n",
    "\n",
    "    #ResNet-50\n",
    "    net =  ResNet(bottleNeck,[3,4,6,3])\n",
    "    net.to(device)\n",
    "    costFunc = torch.nn.CrossEntropyLoss()\n",
    "    optimizer =  torch.optim.SGD(net.parameters(),lr=0.02,momentum=0.9)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        closs = 0\n",
    "        for i,batch in enumerate(trainset,0):\n",
    "            data,output = batch\n",
    "            data,output = data.to(device),output.to(device)\n",
    "            prediction = net(data)\n",
    "            loss = costFunc(prediction,output)\n",
    "            closs = loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print every 1000th time\n",
    "            if i%100 == 0:\n",
    "                print('[%d  %d] loss: %.4f'% (epoch+1,i+1,closs/1000))\n",
    "                closs = 0\n",
    "        correctHits=0\n",
    "        total=0\n",
    "        for batches in testset:\n",
    "            data,output = batches\n",
    "            data,output = data.to(device),output.to(device)\n",
    "            prediction = net(data)\n",
    "            _,prediction = torch.max(prediction.data,1)  #returns max as well as its index\n",
    "            total += output.size(0)\n",
    "            correctHits += (prediction==output).sum().item()\n",
    "        print('Accuracy on epoch ',epoch+1,'= ',str((correctHits/total)*100))\n",
    "\n",
    "    correctHits=0\n",
    "    total=0\n",
    "    for batches in testset:\n",
    "        data,output = batches\n",
    "        data,output = data.to(device),output.to(device)\n",
    "        prediction = net(data)\n",
    "        _,prediction = torch.max(prediction.data,1)  #returns max as well as its index\n",
    "        total += output.size(0)\n",
    "        correctHits += (prediction==output).sum().item()\n",
    "    print('Accuracy = '+str((correctHits/total)*100))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseBlock(nn.Module):\n",
    "\n",
    "    expansion = 1\n",
    " \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, dim_change = None):\n",
    "        super().__init__()  \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride = stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels) \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.dim_change = dim_change\n",
    "\n",
    "    def forward(self, x):\n",
    "        #save the residue`\n",
    "        res = x \n",
    "        output = F.relu(self.bn1(self.conv1(x))) \n",
    "        output = self.bn2(self.conv2(output)) \n",
    "\n",
    "#if we pass nothing to class then dim_change = None, as result identity will not changed\n",
    "#When we pass dim_change = \"some convolution layer\" as class constructor argument, It will dim_change the identity by passing it to a 1x1 convolution layer to sucessfully perform addition. this layer will dim_change the identity through code as mentioned\n",
    "        \n",
    "        if self.dim_change is not None:\n",
    "            res = self.dim_change(res)\n",
    "\n",
    "        output += res \n",
    "        output = F.relu(output)\n",
    "\n",
    "        return output \n"
   ]
  }
 ]
}