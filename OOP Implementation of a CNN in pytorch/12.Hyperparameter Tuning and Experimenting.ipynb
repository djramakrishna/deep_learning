{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599368272246",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth = 120) \n",
    "torch.set_grad_enabled(True) \n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter #allows to send data to tensorboard files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "        \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "\n",
    "    def forward(self, t):\n",
    "        \n",
    "        # (1) input layer\n",
    "        t = t\n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride =2)\n",
    "\n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride =2)\n",
    "\n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "       \n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t) \n",
    "\n",
    "        # (6) ouput layer\n",
    "        t = self.out(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'  \n",
    "    ,train=True    \n",
    "    ,download=True \n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paramter lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_list = [100, 1000, 10000]\n",
    "lr_list = [0.01, 0.001, 0.0001, 0.00001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch : 1 total_correct: 51704 loss : 22485.33167243004\nepoch : 1 total_correct: 51704 loss : 22485.33167243004\nepoch : 1 total_correct: 51704 loss : 22485.33167243004\nepoch : 1 total_correct: 51704 loss : 22485.33167243004\nepoch : 1 total_correct: 51704 loss : 22485.33167243004\nepoch : 1 total_correct: 51704 loss : 22485.33167243004\nepoch : 1 total_correct: 51704 loss : 22485.33167243004\nepoch : 1 total_correct: 51704 loss : 22485.33167243004\nepoch : 1 total_correct: 51704 loss : 22485.33167243004\nepoch : 1 total_correct: 51704 loss : 22485.33167243004\nepoch : 1 total_correct: 51185 loss : 23778.030727803707\nepoch : 1 total_correct: 51185 loss : 23778.030727803707\nepoch : 1 total_correct: 51185 loss : 23778.030727803707\nepoch : 1 total_correct: 51185 loss : 23778.030727803707\nepoch : 1 total_correct: 51185 loss : 23778.030727803707\nepoch : 1 total_correct: 51185 loss : 23778.030727803707\nepoch : 1 total_correct: 51185 loss : 23778.030727803707\nepoch : 1 total_correct: 51185 loss : 23778.030727803707\nepoch : 1 total_correct: 51185 loss : 23778.030727803707\nepoch : 1 total_correct: 51185 loss : 23778.030727803707\nepoch : 1 total_correct: 51629 loss : 22636.034370958805\nepoch : 1 total_correct: 51629 loss : 22636.034370958805\nepoch : 1 total_correct: 51629 loss : 22636.034370958805\nepoch : 1 total_correct: 51629 loss : 22636.034370958805\nepoch : 1 total_correct: 51629 loss : 22636.034370958805\nepoch : 1 total_correct: 51629 loss : 22636.034370958805\nepoch : 1 total_correct: 51629 loss : 22636.034370958805\nepoch : 1 total_correct: 51629 loss : 22636.034370958805\nepoch :1 total_correct: 51629 loss : 22636.034370958805\nepoch : 1 total_correct: 51629 loss : 22636.034370958805\nepoch : 1 total_correct: 50472 loss : 25766.00719690323\nepoch : 1 total_correct: 50472 loss : 25766.00719690323\nepoch : 1 total_correct: 50472 loss : 25766.00719690323\nepoch : 1 total_correct: 50472 loss : 25766.00719690323\nepoch : 1 total_correct: 50472 loss : 25766.00719690323\nepoch : 1 total_correct: 50472 loss : 25766.00719690323\nepoch : 1 total_correct: 50472 loss : 25766.00719690323\nepoch : 1 total_correct: 50472 loss : 25766.00719690323\nepoch : 1 total_correct: 50472 loss : 25766.00719690323\nepoch : 1 total_correct: 50472 loss : 25766.00719690323\nepoch : 1 total_correct: 51451 loss : 230962.13425695896\nepoch : 1 total_correct: 51451 loss : 230962.13425695896\nepoch : 1 total_correct: 51451 loss : 230962.13425695896\nepoch : 1 total_correct: 51451 loss : 230962.13425695896\nepoch : 1 total_correct: 51451 loss : 230962.13425695896\nepoch : 1 total_correct: 51451 loss : 230962.13425695896\nepoch : 1 total_correct: 51451 loss : 230962.13425695896\nepoch : 1 total_correct: 51451 loss : 230962.13425695896\nepoch : 1 total_correct: 51451 loss : 230962.13425695896\nepoch : 1 total_correct: 51451 loss : 230962.13425695896\nepoch : 1 total_correct: 51126 loss : 239754.37320768833\nepoch : 1 total_correct: 51126 loss : 239754.37320768833\nepoch : 1 total_correct: 51126 loss : 239754.37320768833\nepoch : 1 total_correct: 51126 loss : 239754.37320768833\nepoch : 1 total_correct: 51126 loss : 239754.37320768833\nepoch : 1 total_correct: 51126 loss : 239754.37320768833\nepoch : 1 total_correct: 51126 loss : 239754.37320768833\nepoch : 1 total_correct: 51126 loss : 239754.37320768833\nepoch : 1 total_correct: 51126 loss : 239754.37320768833\nepoch : 1 total_correct: 51126 loss : 239754.37320768833\nepoch : 1 total_correct: 51440 loss : 230253.73467803\nepoch : 1 total_correct: 51440 loss : 230253.73467803\nepoch : 1 total_correct: 51440 loss : 230253.73467803\nepoch : 1 total_correct: 51440 loss : 230253.73467803\nepoch : 1 total_correct: 51440 loss : 230253.73467803\nepoch : 1 total_correct: 51440 loss : 230253.73467803\nepoch : 1 total_correct: 51440 loss : 230253.73467803\nepoch : 1 total_correct: 51440 loss : 230253.73467803\nepoch : 1 total_correct: 51440 loss : 230253.73467803\nepoch : 1 total_correct: 51440 loss : 230253.73467803\nepoch : 1 total_correct: 50983 loss : 241117.29529500008\nepoch : 1 total_correct: 50983 loss : 241117.29529500008\nepoch : 1 total_correct: 50983 loss : 241117.29529500008\nepoch : 1 total_correct: 50983 loss : 241117.29529500008\nepoch : 1 total_correct: 50983 loss : 241117.29529500008\nepoch : 1 total_correct: 50983 loss : 241117.29529500008\nepoch : 1 total_correct: 50983 loss : 241117.29529500008\nepoch : 1 total_correct: 50983 loss : 241117.29529500008\nepoch : 1 total_correct: 50983 loss : 241117.29529500008\nepoch : 1 total_correct: 50983 loss : 241117.29529500008\nepoch : 1 total_correct: 51181 loss : 2390490.138977766\nepoch : 1 total_correct: 51181 loss : 2390490.138977766\nepoch : 1 total_correct: 51181 loss : 2390490.138977766\nepoch : 1 total_correct: 51181 loss : 2390490.138977766\nepoch : 1 total_correct: 51181 loss : 2390490.138977766\nepoch : 1 total_correct: 51181 loss : 2390490.138977766\nepoch : 1 total_correct: 51181 loss : 2390490.138977766\nepoch : 1 total_correct: 51181 loss : 2390490.138977766\nepoch : 1 total_correct: 51181 loss : 2390490.138977766\nepoch : 1 total_correct: 51181 loss : 2390490.138977766\nepoch : 1 total_correct: 51628 loss : 2266778.21546793\nepoch : 1 total_correct: 51628 loss : 2266778.21546793\nepoch : 1 total_correct: 51628 loss : 2266778.21546793\nepoch : 1 total_correct: 51628 loss : 2266778.21546793\nepoch : 1 total_correct: 51628 loss : 2266778.21546793\nepoch : 1 total_correct: 51628 loss : 2266778.21546793\nepoch : 1 total_correct: 51628 loss : 2266778.21546793\nepoch : 1 total_correct: 51628 loss : 2266778.21546793\nepoch : 1 total_correct: 51628 loss : 2266778.21546793\nepoch : 1 total_correct: 51628 loss : 2266778.21546793\nepoch : 1 total_correct: 51602 loss : 2275865.3604984283\nepoch : 1 total_correct: 51602 loss : 2275865.3604984283\nepoch : 1 total_correct: 51602 loss : 2275865.3604984283\nepoch : 1 total_correct: 51602 loss : 2275865.3604984283\nepoch : 1 total_correct: 51602 loss : 2275865.3604984283\nepoch : 1 total_correct: 51602 loss : 2275865.3604984283\nepoch : 1 total_correct: 51602 loss : 2275865.3604984283\nepoch : 1 total_correct: 51602 loss : 2275865.3604984283\nepoch : 1 total_correct: 51602 loss : 2275865.3604984283\nepoch : 1 total_correct: 51602 loss : 2275865.3604984283\nepoch : 1 total_correct: 51477 loss : 2300860.1872622967\nepoch : 1 total_correct: 51477 loss : 2300860.1872622967\nepoch : 1 total_correct: 51477 loss : 2300860.1872622967\nepoch : 1 total_correct: 51477 loss : 2300860.1872622967\nepoch : 1 total_correct: 51477 loss : 2300860.1872622967\nepoch : 1 total_correct: 51477 loss : 2300860.1872622967\nepoch : 1 total_correct: 51477 loss : 2300860.1872622967\nepoch :1 total_correct: 51477 loss : 2300860.1872622967\nepoch : 1 total_correct: 51477 loss : 2300860.1872622967\nepoch : 1 total_correct: 51477 loss : 2300860.1872622967\n"
    }
   ],
   "source": [
    "for batch_size in batch_size_list:\n",
    "    for lr in lr_list:\n",
    "        network = Network()\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)\n",
    "        optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "        images,labels = next(iter(train_loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        comment = f'batch_size={batch_size} lr={lr}' #create a string called as comment nd pass it as a comment to summarywriter\n",
    "\n",
    "        tb = SummaryWriter(comment=comment)\n",
    "        tb.add_image('images', grid)\n",
    "        tb.add_graph(network, images)\n",
    "\n",
    "        for epoch in range(2):\n",
    "    \n",
    "            total_loss = 0\n",
    "            total_correct = 0\n",
    "    \n",
    "#batch = next(iter(train_loader)) # Get a single batch\n",
    "\n",
    "            for batch in train_loader: #get batch\n",
    "                images, labels = batch #unpack the batch\n",
    "\n",
    "                preds = network(images) #pass batch\n",
    "                loss = F.cross_entropy(preds, labels) #calculate loss\n",
    "    \n",
    "                optimizer.zero_grad() #pytorch accumulates the grad after each pass of the batch so we make sure it's zero\n",
    "                loss.backward() #calc gradients \n",
    "                optimizer.step() #update weights #each time we pass a batch the weights are updates, so if we have 100 batches, it updates 100 times and takes 100 steps towards the minimum of the loss function\n",
    "\n",
    "########account loss calc for the batch size \n",
    "                total_loss += loss.item()*batch_size \n",
    "                total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "            tb.add_scalar('Loss', total_loss, epoch)\n",
    "            tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "            tb.add_scalar('Accuracy', total_correct/len(train_set), epoch)\n",
    "\n",
    "    #tb.add_histogram('con1.bias',network.conv1.bias,epoch)\n",
    "    #tb.add_histogram('con1.weight',network.conv1.weight,epoch)\n",
    "    #tb.add_histogram('con1.weight.grad',network.conv1.weight.grad,epoch)\n",
    "\n",
    "    #############this below code works for all layers in the network\n",
    "        for name,weight in network.named_parameters():\n",
    "            tb.add_histogram(name, weight, epoch)\n",
    "            tb.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
    "\n",
    "            print('epoch :', epoch, 'total_correct:', total_correct, 'loss :', total_loss)\n",
    "\n",
    "        tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "conv1.weight torch.Size([6, 1, 5, 5])\nconv1.bias torch.Size([6])\nconv2.weight torch.Size([12, 6, 5, 5])\nconv2.bias torch.Size([12])\nfc1.weight torch.Size([120, 192])\nfc1.bias torch.Size([120])\nfc2.weight torch.Size([60, 120])\nfc2.bias torch.Size([60])\nout.weight torch.Size([10, 60])\nout.bias torch.Size([10])\n"
    }
   ],
   "source": [
    "for name,weight in network.named_parameters():\n",
    "    print(name, weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "conv1.weight.grad torch.Size([6, 1, 5, 5])\nconv1.bias.grad torch.Size([6])\nconv2.weight.grad torch.Size([12, 6, 5, 5])\nconv2.bias.grad torch.Size([12])\nfc1.weight.grad torch.Size([120, 192])\nfc1.bias.grad torch.Size([120])\nfc2.weight.grad torch.Size([60, 120])\nfc2.bias.grad torch.Size([60])\nout.weight.grad torch.Size([10, 60])\nout.bias.grad torch.Size([10])\n"
    }
   ],
   "source": [
    "for name,weight in network.named_parameters():\n",
    "    print(f'{name}.grad', weight.grad.shape)  #name of the layer, and add .grad to it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## But here we're using too many for loops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product  #computes cartesian product given multiple list inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(lr = [0.01,0.001], \n",
    "                 batch_size = [10,100,1000], \n",
    "                 shuffle = [True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[0.01, 0.001], [10, 100, 1000], [True, False]]"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "param_values = [v for v in parameters.values()]\n",
    "param_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.01 10 True\n0.01 10 False\n0.01 100 True\n0.01 100 False\n0.01 1000 True\n0.01 1000 False\n0.001 10 True\n0.001 10 False\n0.001 100 True\n0.001 100 False\n0.001 1000 True\n0.001 1000 False\n"
    }
   ],
   "source": [
    "for lr, batch_size, shuffle in product(*param_values): #star indicates each value of the list as an argument opposed to treating list itself as an argument\n",
    "    print(lr, batch_size, shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above allows us to work in a single loop no matter how many parameters we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr, batch_size, shuffle in product(*param_values):\n",
    "    comment = f'batch_size = {batch_size} lr = {lr} shuffle={shuffle}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}