{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599476740805",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth = 120) \n",
    "torch.set_grad_enabled(True) \n",
    "\n",
    "from itertools import product #computes cartesian product given multiple list inputs  \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter #allows to send data to tensorboard files \n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod #The main thing to note about using this class is that it has a static method called get_runs(). This method will get the runs for us that it builds based on the parameters we pass in.\n",
    "    def get_runs(params):\n",
    "\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "        \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "\n",
    "    def forward(self, t):\n",
    "        \n",
    "        # (1) input layer\n",
    "        t = t\n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride =2)\n",
    "\n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride =2)\n",
    "\n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "       \n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t) \n",
    "\n",
    "        # (6) ouput layer\n",
    "        t = self.out(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'  \n",
    "    ,train=True    \n",
    "    ,download=True \n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RunManager helps us to pull out the following clutter of tensorboard calls and also add additional functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "            tb.add_scalar('Loss', total_loss, epoch)\n",
    "            tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "            tb.add_scalar('Accuracy', total_correct/len(train_set), epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        for name,weight in network.named_parameters():\n",
    "  #\n",
    "            tb.add_histogram(name, weight, epoch)\n",
    "   #\n",
    "            tb.add_histogram(f'{name}.grad', weight.grad, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract a class - refactoring techniques \n",
    "\n",
    "class Epoch():\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.loss = 0\n",
    "        self.num_correct = 0\n",
    "        self.start_time = None \n",
    "\n",
    "#Then, we'll replace these class variable with an instance of the Epoch class.\n",
    "#We might even change the count variable to have a more intuitive name, like say number or id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    ,batch_size = [1000, 10000]   \n",
    ")\n",
    "m = RunManager()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    \n",
    "    network = Network()\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size = run.batch_size)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "\n",
    "    m.begin_run(run, network, train_loader)\n",
    "\n",
    "    for epoch in range(2):\n",
    "        m.begin_epoch()\n",
    "        for batch in train_loader:\n",
    "\n",
    "                images, labels = batch \n",
    "                preds = network(images) \n",
    "                loss = F.cross_entropy(preds, labels) \n",
    "                optimizer.zero_grad()               \n",
    "                loss.backward()          \n",
    "                optimizer.step()\n",
    "                \n",
    "                m.track_loss(loss)\n",
    "                m.track_num_correct(preds, labels)\n",
    "\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "\n",
    "m.save('results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch and the GPU : CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(1,1,28,28)\n",
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t.cuda()\n",
    "newtork = network.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "gpu_pred = network(t)\n",
    "gpu_pred.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t.cpu()\n",
    "network = network.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "cpu_pred = network(t)\n",
    "cpu_pred.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([[1,2],[3,4]])\n",
    "\n",
    "t2= torch.tensor([[5,6],[7,8]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(device(type='cpu'), device(type='cpu'))"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "t1.device, t2.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "t1 = t1.to('cuda')\n",
    "t1.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n"
    }
   ],
   "source": [
    "try : t1+t2\n",
    "except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n"
    }
   ],
   "source": [
    "try : t2+t1\n",
    "except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = t2.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 6,  8],\n        [10, 12]], device='cuda:0')"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "t1+t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with NN modules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what is putting network on a device ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "conv1.weight \t\t\t torch.Size([6, 1, 5, 5])\nconv1.bias \t\t\t torch.Size([6])\nconv2.weight \t\t\t torch.Size([12, 6, 5, 5])\nconv2.bias \t\t\t torch.Size([12])\nfc1.weight \t\t\t torch.Size([120, 192])\nfc1.bias \t\t\t torch.Size([120])\nfc2.weight \t\t\t torch.Size([60, 120])\nfc2.bias \t\t\t torch.Size([60])\nout.weight \t\t\t torch.Size([10, 60])\nout.bias \t\t\t torch.Size([10])\n"
    }
   ],
   "source": [
    "for name, param in network.named_parameters():\n",
    "    print(name, '\\t\\t\\t', param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cpu  conv1.weight\ncpu  conv1.bias\ncpu  conv2.weight\ncpu  conv2.bias\ncpu  fc1.weight\ncpu  fc1.bias\ncpu  fc2.weight\ncpu  fc2.bias\ncpu  out.weight\ncpu  out.bias\n"
    }
   ],
   "source": [
    "for name, p in network.named_parameters():\n",
    "    print(p.device,'',name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network isnt on device, the paramters are on the device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Network(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=192, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=60, bias=True)\n  (out): Linear(in_features=60, out_features=10, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "network.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cpu  conv1.weight\ncpu  conv1.bias\ncpu  conv2.weight\ncpu  conv2.bias\ncpu  fc1.weight\ncpu  fc1.bias\ncpu  fc2.weight\ncpu  fc2.bias\ncpu  out.weight\ncpu  out.bias\n"
    }
   ],
   "source": [
    "for name, p in network.named_parameters():\n",
    "    print(p.device,'',name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Network(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=192, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=60, bias=True)\n  (out): Linear(in_features=60, out_features=10, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "network.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cuda:0  conv1.weight\ncuda:0  conv1.bias\ncuda:0  conv2.weight\ncuda:0conv2.bias\ncuda:0  fc1.weight\ncuda:0  fc1.bias\ncuda:0  fc2.weight\ncuda:0  fc2.bias\ncuda:0  out.weight\ncuda:0  out.bias\n"
    }
   ],
   "source": [
    "for name, p in network.named_parameters():\n",
    "    print(p.device,'',name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([1, 1, 28, 28])"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "sample = torch.ones(1,1,28,28)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\n"
    }
   ],
   "source": [
    "try : network(sample)\n",
    "except Exception as e : print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 0.0937,  0.0243,  0.0549,  0.1752, -0.0259,  0.0533, -0.1197, -0.0053,  0.1205,  0.0757]], device='cuda:0',\n       grad_fn=<AddmmBackward>)\n"
    }
   ],
   "source": [
    "try:\n",
    "    pred = network(sample.to('cuda'))\n",
    "    print(pred)\n",
    "except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunManager():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "\n",
    "        self.run_params = None \n",
    "        self.run_count = 0\n",
    "        self.run_data = []  #track param,results for each epoch for each run\n",
    "        self.run_start_time = None  #run durations\n",
    "\n",
    "        self.network = None #save network\n",
    "        self.loader = None #save data loader for run\n",
    "        self.tb = None #summarywriter for tensorboard\n",
    "\n",
    "\n",
    "#Anytime we see this, we need to be thinking about removing these prefixes. (epoch_count, epoch_loss, ....)\n",
    "# Data that belongs together should be together. \n",
    "# This is done by encapsulating the data inside of a class.\n",
    "#this is done in next cell\n",
    "\n",
    "    def begin_run(self, run, network, loader):\n",
    "\n",
    "        self.run_start_time = time.time()\n",
    "\n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "\n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')\n",
    "\n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        self.tb.add_image('images', grid)\n",
    "        self.tb.add_graph(self.network, images.to(getattr(run, 'device', 'cpu')))     ####### getattr is modified - check which device the run for \n",
    "\n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "\n",
    "    def end_epoch(self):\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "\n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "\n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "\n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "\n",
    "        results = OrderedDict()\n",
    "        results['run'] = self.run_count\n",
    "        results['epoch'] = self.epoch_count\n",
    "        results['loss'] = loss\n",
    "        results['accuracy'] = accuracy\n",
    "        results['epoch duration'] = epoch_duration\n",
    "        results['run duration'] = run_duration\n",
    "        for k,v in self.run_params._asdict().items(): results[k] = v\n",
    "        self.run_data.append(results)\n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient='columns')\n",
    "        \n",
    "        clear_output(wait=True) #specific to jy notebooks clear curr o/p and display new data frame\n",
    "        display(df)\n",
    "    \n",
    "    def track_loss(self, loss):\n",
    "        self.epoch_loss += loss.item() * batch[0].shape[0]\n",
    "\n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "    \n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "    @torch.no_grad()\n",
    "\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self, fileName):\n",
    "\n",
    "        pd.DataFrame.from_dict(self.run_data, orient='columns').to_csv(f'{fileName}.csv')\n",
    "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the GPU : Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "track_loss() takes 2 positional arguments but 3 were given",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-2ca05dc629b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_num_correct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: track_loss() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    ,batch_size = [1000, 10000, 20000]\n",
    "    ,num_workers = [0,1]\n",
    "    ,device = ['cuda', 'cpu']   \n",
    ")\n",
    "m = RunManager()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    \n",
    "    device = torch.device(run.device) ## create a pytroch device and pass cpu or cuda\n",
    "    network = Network().to(device) #initialize network on cuda\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size = run.batch_size)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "\n",
    "    m.begin_run(run, network, train_loader)\n",
    "\n",
    "    for epoch in range(1):\n",
    "        m.begin_epoch()\n",
    "        for batch in train_loader:\n",
    "\n",
    "                images = batch[0].to(device) #unpack them & send to device \n",
    "                labels = batch[1].to(device) #unpack them & send to device\n",
    "                preds = network(images) \n",
    "                loss = F.cross_entropy(preds, labels) \n",
    "                optimizer.zero_grad()               \n",
    "                loss.backward()          \n",
    "                optimizer.step()\n",
    "                \n",
    "                m.track_loss(loss)\n",
    "                m.track_num_correct(preds, labels)\n",
    "\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "\n",
    "m.save('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(m.run_data, orient='columns').sort_values('epoch duration') #sorting by run duration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}