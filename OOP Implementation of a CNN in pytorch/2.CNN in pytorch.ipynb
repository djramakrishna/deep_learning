{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599997849813",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build PyTorch CNN - Object Oriented Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second line defines a special method called the class constructor. Class constructors are called when a new instance of the class is created. As parameters, we have self and name.\n",
    "\n",
    "The self parameter gives us the ability to create attribute values that are stored or encapsulated within the object. When we call this constructor or any of the other methods, we don't pass the self parameter. Python does this for us automatically.\n",
    "\n",
    "Argument values for any other parameter are arbitrarily passed by the caller, and these passed values that come in to the method can be used in a calculation or saved and accessed later using self.\n",
    "\n",
    "After we're done with the constructor, we can create any number of specialized methods like this one here that allows a caller to change the name value that was stored in self. All we have to do here is call the method and pass a new value for the name. Let's see this in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lizard: #class declaration\n",
    "    def __init__(self, name): #class constructor (code)\n",
    "        self.name = name #attribute (data)\n",
    "\n",
    "    def set_name(self, name): #method declaration (code)\n",
    "        self.name = name #method implementation (code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "deep\n"
    }
   ],
   "source": [
    " lizard = Lizard('deep')  \n",
    " print(lizard.name) #property that can be grabbed object.attribute_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "new_lizard\n"
    }
   ],
   "source": [
    "lizard.set_name('new_lizard') #function that can be called object.fnc(argument)\n",
    "print(lizard.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn #nn lib for pytorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each layer has two components  1) Transformation (code) 2) collection of weights (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch layers are defined by classes. So in code, our layers are objects \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special class call module in nn. Its base class for all nn modules. All layers extend nn.module class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Extend nn.module base class - create nn class that extends nn module base class\n",
    "\n",
    "2) In class constructors - Define layers as class attributes using pre-built layers from torch.nn\n",
    "\n",
    "3) Implement the forward() method - Use the network’s layer attributes as well as operations from the nn.functional API to define the network’s forward pass.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Network:\n",
    "\n",
    "     def __init__(self):\n",
    "         self.layer = None\n",
    "\n",
    "     def forward(self, t):\n",
    "         t = self.layer(t)\n",
    "         return t\n",
    "\n",
    "# This gives us a simple network class that has a single dummy layer inside the constructor and a dummy implementation for the forward function\n",
    "# The implementation for the forward() function takes in a tensor t and transforms it using the dummy layer. After the tensor is transformed, the new tensor is returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the nn package, there is a class called Module, and it is the base class for all of neural network modules which includes layers.\n",
    "\n",
    "This means that all of the layers in PyTorch extend the nn.Module class and inherit all of PyTorch’s built-in functionality within the nn.Module class. In OOP this concept is known as inheritance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our Network class extend nn.Module, we must do two additional things:\n",
    "\n",
    "Specify the nn.Module class in parentheses on line 1.\n",
    "Insert a call to the super class constructor on line 3 inside the constructor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending pytorch nn.module class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layer = None\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = self.layer(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a simple network class that has a single dummy layer inside the constructor and a dummy implementation for the forward function.\n",
    "\n",
    "The implementation for the forward() function takes in a tensor t and transforms it using the dummy layer. After the tensor is transformed, the new tensor is returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define The Network’s Layers As Class Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):  #simple network to pytorch nn \n",
    "\n",
    "     def __init__(self):\n",
    "         \n",
    "         super().__init__()    #insert a call to super class constructor inside the constructor\n",
    "         self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5) #layer 1 as class attribute \n",
    "         #in_channels of the first convolutional layer depend on the number of color channels in input image\n",
    "         self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 5) #layer 2 as class attribute\n",
    "\n",
    "         self.fc1 = nn.Linear(in_features = 12*4*4, out_features = 120) #layer 3 as class attribute\n",
    "         self.fc2 = nn.Linear(in_features = 120, out_features = 60) #layer 4 as class attribute\n",
    "         self.out = nn.Linear(in_features = 60, out_features = 10) #layer 5 as class attribute\n",
    "\n",
    "     def forward(self, t):\n",
    "         #implement the forward pass\n",
    "         return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Network(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=192, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=60, bias=True)\n  (out): Linear(in_features=60, out_features=10, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "network = Network() #instance of a network by calling a constructor\n",
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Layers - PyTorch Deep Neural Network Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of our layers extends PyTorch's neural network Module class. For each layer, there are two primary items encapsulated inside, a forward function definition and a weight tensor.\n",
    "\n",
    "The weight tensor inside each layer contains the weight values that are updated as the network learns during the training process, and this is the reason we are specifying our layers as attributes inside our Network class.\n",
    "\n",
    "PyTorch's neural network Module class keeps track of the weight tensors inside each layer. The code that does this tracking lives inside the nn.Module class, and since we are extending the neural network module class, we inherit this functionality automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) #the names in_channels, out_channels etc are the parameter and values passed into them are arguments  \n",
    "        #here in the above one input channel convolved by 6 different filters, giving 6  output channels\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120) #we need to flatten for linear so 12 but why 4*4 ? 4*4 is the last size of  the image pass through the 2 layer CNN\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # implement the forward pass\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters - parameters whose values are chose manually and arbitrarily\n",
    "# We chose them trial and error \n",
    "\n",
    "####The parameters we choose manually in CNN lahyers - \n",
    "\n",
    "#in_channels of first convolutional layer - for grey it is 1\n",
    "\n",
    "#out_channels (sets no of filter, one filter gives one output channel)\n",
    "\n",
    "#kernel_size (sets filter size filter and kernal are interchangable)\n",
    "\n",
    "#out_features (sets size of output tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data dependent hp are param that values depend on the data\n",
    "\n",
    "#out_feature of last linear layer - has labels like 10 outputs \n",
    "\n",
    "#in above examples data dependent hp are - \n",
    "\n",
    "# all in_channels  & in_features  \n",
    "# final out_features"
   ]
  }
 ]
}